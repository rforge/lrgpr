%
% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is
% likely to be overwritten.
%

% Compile:
% library( highlight ) 
% driver <- HighlightWeaveLatex(size='tiny')
% Sweave('annotate.Rnw', driver = driver ); tools::texi2dvi('annotate.tex', pdf=TRUE)

% Sweave('lrgpr.Rnw'); tools::texi2dvi('lrgpr.tex', pdf=TRUE)

%  file.remove("lrgpr.aux"); Sweave('lrgpr.Rnw');  tools::texi2dvi('lrgpr.tex', pdf=T, clean=F); 

% sed 's/ et~al./, et al./g' lrgpr.aux | tail


% sed -i 's/ et~al./, et al./g' lrgpr.bbl; sed -i 's/~//g' lrgpr.bbl

\documentclass[11pt]{article}

\usepackage{fullpage}
%\usepackage{hyperref}
\usepackage{times}
\usepackage{verbatim}
\usepackage{amsmath, amssymb}

\newcommand{\proglang}[1]{\textsf{#1}}
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\newcommand{\code}[1]{\texttt{#1}}


\bibliographystyle{elsart-harv2}
\usepackage[author,year]{natbib}
%\bibpunct{(}{)}{;}{a}{,}{,}

\bibcite{Hoffman2013c}{{1}{2013}{{Hoffman}}{{}}}
\bibcite{Kang2010}{{2}{2010}{{Kang, et al.}}{{Kang, Sul, Service, Zaitlen, Kong, Freimer, Sabatti, and Eskin}}}
\bibcite{Lippert2011}{{3}{2011}{{Lippert, et al.}}{{Lippert, Listgarten, Liu, Kadie, Davidson, and Heckerman}}}
\bibcite{Listgarten2012}{{4}{2012}{{Listgarten, et al.}}{{Listgarten, Lippert, Kadie, Davidson, Eskin, and Heckerman}}}
\bibcite{Yang2011e}{{5}{2011}{{Yang, et al.}}{{Yang, Lee, Goddard, and Visscher}}}
\bibcite{Zhou2012}{{6}{2012}{{Zhou and Stephens}}{{}}}

<<echo=FALSE,print=FALSE>>=
prettyVersion <- packageDescription("lrgpr")$Version
prettyDate <- format(Sys.Date(), "%B %e, %Y")
@

\author{Gabriel E. Hoffman}
\title{\pkg{lrgpr}: Low Rank Gaussian Process Regression}
\date{\pkg{lrgpr} version \Sexpr{prettyVersion} as of \Sexpr{prettyDate}}

\begin{document}
\maketitle{}

\abstract{
  \noindent
  The \pkg{lrgpr} package provides an interactive \proglang{R} interface for fitting linear mixed models, also known as Gaussian Process Regression, on very large datasets.  The package provides user-friendly interfaces for the linear mixed model and a computationally efficent extension termed \underline{L}ow \underline{R}ank \underline{G}aussian \underline{P}rocess \underline{R}egression, as well as standard linear and logistic regression models.  \pkg{lrgpr} allows fitting millions of regression models on a desktop computer by using an efficient implementation, parallelization and out-of-core computing for datasets that are too large to fit in main memory.  
 %The linear model model, also known as Gaussian Process Regression (GPR), is widely used in statistical genetics to account for the confounding effects of kinship and population structure.  .  
%
 % Designed to be user-friendly and following the built-in \pkg{glm} interface, 
}

\section{Overview}

% Remove R prompt ">"
<<echo=F>>=
options(prompt = "> ")
options(continue = " ")
library(lrgpr)
library(aod)
@

Genome-wide association studies (GWAS) are a widely used to identify genetic variants that are associated with variation in a phenotype of interest.  Tests of association usually take the form of statistical hypothesis tests in a regression model that accounts for known confounding variables such as sex.  Yet due to complex nature of GWAS datasets, more sophisticated methods are used in order to maintain power while controling the false positive rate.  The linear mixed model is the state-of-the-art method to account for the confounding effects of kinship and population structure in GWAS analysis, and much recent work as focused on this approach \citep{Hoffman2013c, Listgarten2012, Lippert2011, Kang2010, Zhou2012}.\\
\\
To date, most software for GWAS data has been designed for a ``one-size-fits-all" analysis.  Yet as GWAS datasets have become increasing complex and heterogeneous, there is growing potential for interactive, exploratory data analysis.  The \pkg{lrgpr} package privdes a user-friendly, interactive and computationally efficient analysis framework that faciliates custom, exploratory analysis of large GWAS datasets.\\ 
\\
The \pkg{lrgpr} package provides:
\begin{itemize}
 \item Seamless, interactive \proglang{R} interface to aribtarily large datasets through \pkg{bigmemory}'s \verb|big.matrix|
 \item Scalable linear or logistic regression for millions of hypothesis tests using \verb|glmApply|
 \item Fitting a full or low rank linear mixed model with \verb|lrgpr|
 \item Data-adaptive construction of the genetic similarity matrix for the linear mixed model
 \item Scalable linear mixed model regression for millions of hypothesis tests using \verb|lrgprApply|
 \item Ability to define arbitrary interaction models and perform composite hypothesis tests with \verb|glmApply|, \verb|lrgpr| and \verb|lrgprApply|
\end{itemize}

\section{Dependencies and installation}

\pkg{lrgpr} has some dependencies that may not be installed on your system.  Installation requires the GNU Scientific Library (GSL) and Boost C++ libraries. On Ubuntu these can be automatically installed:

\begin{verbatim}
sudo apt-get install libboost-all-dev libgsl0-dev
\end{verbatim}
\noindent
On Redhat there should be a similar command using \verb|yum|.  Alternatively, you can install them manually from source:
\begin{itemize}
 \item GSL: \verb|http://www.gnu.org/software/gsl/|
 \item Boost: \verb|http://www.boost.org/users/download/| 
\end{itemize} 
\noindent
\pkg{lrgpr} also depends on a number of \proglang{R} packages that can be installed from CRAN:

<<eval=FALSE>>=
pkgs = c("Rcpp", "RcppGSL", "RcppProgress", "MASS", "parallel", "doParallel", 
"formula.tools", "BH", "bigmemory", "aod")
install.packages(pkgs)
@
\pkg{lrgpr} requres bigmemory >= v4.4.7, so  install this from R-Forge: 
<<eval=FALSE>>=
install.packages("bigmemory", repos="http://R-Forge.R-project.org")
@

\noindent
Once the dependencies are installed, you can install \pkg{lrgpr}:

\begin{verbatim}
R CMD INSTALL lrgpr_0.0.1.tar.gz
\end{verbatim}

\section{Using the \texttt{big.matrix} format }

\proglang{R} typically stores all data in memory (i.e. RAM) for fast access.  However, GWAS datasets can easily be too lage to store in memory.  For example, a dataset with 10,000 individuals and 1,000,000 SNPs would require $\sim80$ Gb to store in \proglang{R} in its standard format (i.e. as a \texttt{double}), and much larger datasets are now very common.  Instead, \pkg{lrgpr} uses \pkg{bigmemory}'s \texttt{big.matrix} format to store a very large dataset in binary form directly on the hard drive and avoid using RAM while still allowing interactive access to the data.  Thus the \texttt{big.matrix} format allows analysis of arbitrarily large datasets on any machine with sufficient hard drive capacity.
\\
\\
Arbitrary data can be converted to \texttt{big.matrix} format using \pkg{bigmemory}'s \texttt{write.big.matrix}.  Alternatively, large GWAS data can be converted more efficently:

<<echo=T>>=
# Path to Plink files
path = system.file(package = 'lrgpr')
tped_file = paste(path, "/extdata/test.tped", sep="")
fam_file = paste(path, "/extdata/test.tfam", sep="")
map_file = paste(path, "/extdata/test.map", sep="")
@

<<echo=T,results=hide>>=
# Convert TPED file to binary format
# Create a binary data file: test.binary
# 	and a binary file describing this data: test.binary_descr
convertToBinary(tped_file, "./test.binary", "TPED")
@
\noindent
Supported GWAS data formats include TPED, GEN and DOSAGE.\\
\\
Data is loaded into \proglang{R} by pointing a variable to the description file:

<<echo=T>>=
# attach data by reading the description file
X <- attach.big.matrix("./test.binary_descr")
@
\noindent
Note that this data is not loaded into memory. Instead \verb|X| points to the location of the data on the hard drive, and the data is loaded into memory only when the user asks for it.  The user can treat \verb|X| as a standard \proglang{R} \verb|matrix| with the caveat that user must be carefull not to load too much data into memory at the same time.  For example, the $10^{th}$ SNP can be accessed seamlessly: 

<<echo=T,results=hide>>=
# data is only loaded into memory when it is accessed
X[,10]
@
\noindent
and the user can perform abitrary operations on each column individually without loading the whole dataset at the same time:

<<echo=T,results=hide>>=
# data is only loaded into memory when it is accessed
column_means = c()

for(j in 1:ncol(X)){
	column_means[j] = mean(X[,j])
}
@
\noindent
Accessing the data in this way creates a standard \proglang{R} \verb|matrix| that can be passed to any function. Thus the user can process \verb|X| as if it were stored in memory; the complexity of storing the data on the hard drive is completely hidden from the user.\\
\\
Processing the entire dataset in \proglang{R} can be costly for large datasets, so \pkg{lrgpr} provides functions to report common statistics more efficiently by performing all computations in \proglang{C/C++}:

<<echo=T,results=hide>>=
# Report allele frequencies using C/C++ backend
freq = getAlleleFreq(X)
@

\section{Regression with \proglang{R}'s \texttt{glm}}

\proglang{R} fits generalized linear models using the \verb|glm| function that provides flexability in defining the regression model.  I describe \verb|glm| very briefly here so that I can later describe how \pkg{lrgpr} mirrors this functionality.  For example, we can read Plink's FAM file and fit a simple model:

<<echo=T,results=hide>>=
# Read FAM file
FAM = read.fam(fam_file)
y = FAM$phenotype
sex = FAM$sex
@

<<echo=T,results=hide>>=
# Fit a linear model
fit = glm( y ~ sex )
@
\noindent
We can see the model coefficients and statistics:
<<echo=T,results=hide>>=
# Simple view
fit
@
<<echo=T,results=hide>>=
# Expanded view
summary(fit)
@
and plot model diagnostics:

<<>>=
# Plot diagnostics
par(mfrow=c(2,2))
plot(fit)
@

\noindent
The user can also specify and perform hypothesis tests on more complex models involving interations:
<<echo=T,results=hide>>=
# Fit a linear model
fit = glm( y ~ sex + X[,10]*X[,100])
@

<<echo=T,results=hide>>=
# Composite hypothesis test of additive and interaction terms for the two markers
# Note that wald.test is from the aod package
wald.test(vcov(fit), coef(fit), Terms=3:5)
@

\section{Fitting many regressions with \texttt{glmApply}}

Analysis of GWAS data involves fitting a regression model for each SNP individually.  The user could write a simple \verb|for| loop that calls the \verb|glm| function, but the computation can be accelerated by doing the calculation in the \proglang{C/C++} backend and reporting the results.\\
\\
A standard analysis can be performed with \pkg{lrgpr}'s \verb|glmApply|:

<<echo=T,results=hide>>=
# Standard GWAS regression analysis
pValues = glmApply( y ~ SNP + sex, features=X, terms=2)$pValues
@
where the \verb|formula| follows standard \verb|glm| syntax, \verb|features| specifies the \verb|big.matrix| or standard \proglang{R} \verb|matrix| with columns as genetic markers, and \verb|terms| specifies which variables from the \verb|formula| are in the hypothesis test.  Note that \verb|SNP| is a placeholder for each sucessive column in \verb|features|, and if \verb|terms| is omitted the hypothesis test includes all terms corresponding to \verb|SNP|:
<<echo=T,results=hide>>=
# Standard GWAS regression analysis
pValues = glmApply( y ~ SNP + sex, features=X)$pValues
@
This code is the same as:
<<echo=T,results=hide>>=
pValuesR = c()

for(j in 1:ncol(X)){
	# fit model
	fit = glm(y ~ X[,j] + sex)

	# perform hypothesis test
	pValuesR[j] = wald.test(vcov(fit), coef(fit), Terms=2)$result$chi2[3]
}
@
but calling \verb|glmApply| is simpler and much faster for large datasets.\\
\\
Note that \verb|glmApply| can also efficiently fit multivariate regression models with multiple response variables. See \verb|?glmApply| for details.

\section{Linear mixed models with \texttt{lrgpr}}

The \verb|lrgpr| function fits full and low rank linear mixed models and follows the syntax and behavior of \verb|glm|.\\
\\
The linear mixed model has the form:
\begin{eqnarray*}
\mathbf y &\sim& \mathcal{N}(\mathbf X \boldsymbol\beta, \mathbf K\sigma^2_a + \mathbf I\sigma^2_e),
\end{eqnarray*}
where $\mathbf y \,(n \times 1)$ is the vector of phenotype values, $n$ is the sample size, $\mathbf X \,(n \times c)$ is the design matrix of $c$ fixed effects, $\boldsymbol\beta\,(c \times 1)$ is the vector of coefficients, $\mathbf K \,(n \times n)$ is the genetic similarity matrix (GSM), $\mathbf I \,(n \times n)$ is the identity matrix, $\sigma^2_a$ is the magnitude of the genetic variance, and $\sigma^2_e$ is the magnitude of the residual variance.  The parameters are estimated by maximizing the log-loglihood using the algorithms of \citet{Lippert2011} and \citet{Listgarten2012}.\\
\\
When $\mathbf K$ is full rank, the coefficient estimates and their sample variance are, respectively,  
\begin{eqnarray*}
\hat{\boldsymbol\beta} &=& (\mathbf X^T \mathbf \Omega \mathbf X)^{-1} \mathbf X^T \mathbf \Omega \mathbf y\\ 
\hat{\mathbf \Sigma} &=& (\mathbf X^T \mathbf \Omega \mathbf X)^{-1} \sigma^2_a
\end{eqnarray*}
where $\mathbf \Omega = (\mathbf K + \mathbf I\frac{\sigma^2_e}{\sigma^2_a})^{-1}$ and the values of $\sigma^2_a$ and $\sigma^2_e$ are already estimated by maximum likelihood.  Following standard likelihood theory, the Wald test is
\begin{eqnarray*}
\hat{\boldsymbol\beta}_h^T (\hat{\mathbf \Sigma}_{h})^{-1} \hat{\boldsymbol\beta}_h \sim \chi^2_{|h|}
\end{eqnarray*}
where $h$ specifies the fixed effects being tested and $|h|$ is the number of entries.  When $\mathbf K$ is not full rank the estimates and hypothesis tests are analogous and follow directly from \citet{Listgarten2012}.

\subsection{The genetic similarity matrix and its spectral decomposition}

Following the algorithms of \citet{Lippert2011} and \citet{Listgarten2012}, the genetic similarity matrix enters the linear mixed model only through its spectral decomposition.  There are multiple ways to compute $\mathbf K$ or its spectral decomposition. 

\subsubsection{Full rank linear mixed model }
When the genetic similarity matrix, $\mathbf K$, is based on a genome-wide set of markers, the linear mixed model is full rank.  A number of similarity metrics are widely used \citep{Yang2011e, Kang2010, Zhou2012} and a genetic similarity matrix can easily be imported into \proglang{R} from another program:

<<echo=T, results=hide>>=
# Read in GSM and perform spectral decomposition
K = read.table( paste(path, "/extdata/K.txt", sep="") )
dcmp = eigen(K, symmetric=TRUE)
@ 
\noindent
However, only the spectral decomposition of $\mathbf K$ is needed, and this can be computed directly in \proglang{R}:    

<<echo=T, results=hide>>=
# Prune to every 100th marker
index = seq(1, ncol(X), by=100)
@
<<echo=T, results=hide>>=
# Keep only SNPs where there is variation in this dataset
# With SNP data coded as 0,1,2 screening by the allele frequency would be sufficient
# But with continuous dosage data, we need to consider the variance of the SNP
v = getAlleleVariance(X[,index])

j = index[which(v > .01)]
@
<<echo=T, results=hide>>=
# Perform spectral decomposition on the set of SNPs
# 	after replacing missing values with the per-SNP mean
# Each SNP is centered and scaled
dcmp = svd(scale(set_missing_to_mean(X[,j])))
@
\noindent
We can then fit the linear mixed model using the same syntax as for \verb|glm|:
<<echo=T, results=hide>>=
fit = lrgpr(y ~ sex, dcmp)
@
\vspace{.15cm}
\noindent
{\normalsize \bf Features of lrgpr}
\vspace{.12cm}

\noindent
Since \verb|lrgpr| behaves like \verb|glm| and we can see the model coefficients and statistics:
<<echo=T>>=
# Simple view
fit
@
<<echo=T>>=
# Expanded view
summary(fit)
@
and plot model diagnostics:
\begin{center}
<<fig=T, height=3,width=12>>=
# Plot diagnostics
par(mfrow=c(1,4))
plot(fit)
@
\end{center}

\noindent
The user can also specify and perform hypothesis tests on more complex models involving interations:
<<echo=T,results=hide>>=
# Fit a linear model
fit = lrgpr( y ~ sex + X[,10]*X[,100], dcmp)
@
<<echo=T,results=hide>>=
# Composite hypothesis test of additive and interaction terms for the two markers
wald(fit, terms=3:5)
@
\noindent
This functionality can be used to perform custom, exporatory analysis on arbitrarily large datasets.

\subsubsection{Low rank linear mixed model: (low rank gaussian process regression) }

The full rank linear mixed model can be very computationally expensive for large datasets and a low rank version was proposed to address this issue \citep{Lippert2011,Listgarten2012}.  A low rank GSM, or more precisely its spectral decomposition, can be constructed by using fewer SNPs than the sample size.  Instead of capturing the genome-wide similarity, the GSM can be constructed based on the $k$ SNP's that are most correlated with the phenotype.  Following \citet{Lippert2011} and \citet{Listgarten2012}, we construct the GSM using the most signficant markers from an uncorrected association test:

<<echo=T, results=hide>>=
# Uncorrected single SNP test
pValues = glmApply( y ~ SNP + sex, features=X, terms=2)$pValues
@
<<echo=T, results=hide>>=
# sort markers based on p-value
ord = order(pValues, decreasing=FALSE)
@
\noindent 
Now construct the spectral decomposition from the top $k=100$ SNPs and fit the low rank linear mixed model:
@
<<echo=T, results=hide>>=
k = 100
dcmp = svd(scale(set_missing_to_mean(X[,ord[1:k]])))
@
<<echo=T, results=hide>>=
# Fit the low rank model
fit = lrgpr(y ~ sex, dcmp)
@
\vspace{.15cm}
\noindent
{\normalsize \bf Learning the optimal rank of the low rank linear mixed model}
\vspace{.12cm}

\noindent
We arbitrarily selected the top $k=100$ SNPs above, but following \citet{Listgarten2012} we can use cross-validation to select $k$ based on the data.  Here the cross-validation error is calculated for multiple values of $k$:

<<echo=T, results=hide>>=
# Evaluate cross-validation for multiple rank values
fitcv = cv.lrgpr( y ~ sex, features=X, order=ord, nfolds=2)
@
Instead of performing computationally expensive cross-validation, we can use model criterion such as Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC) or Generalized Cross-Validation (GCV) to select $k$ based on the degrees of freedom for the linear mixed model described by \citet{Hoffman2013c}:   

<<echo=T, results=hide>>=
# Evaluate model criterion 
fitcrit = criterion.lrgpr( y ~ sex, features=X, order=ord )
@
\noindent
We can plot the cross-validation error and model criterion scores:

\begin{center}
<<echo=T, fig=T, height=4, width=8>>=
# Plot the cross-validation and model crition curves
par(mfrow=c(1,2))
plot.cv.lrgpr(fitcv)
plot.criterion.lrgpr(fitcrit) 
@
\end{center}

\noindent
and compute to spectral decomposition of the GSM based on the set of SNPs selected by Generalized Cross-validation:
<<echo=T>>=
k = fitcrit$best$GCV
dcmp = svd(scale(set_missing_to_mean(X[,ord[1:k]])))
@
\noindent
Note that the GCV score is very good proxy for the cross-validation error and most of the difference between these values are driven primarily by the finite sampling in cross-validation.

\subsection{Proximal contamination}

If the random effect includes the marker to be tested, the correlation between the two can decrease power.  More generally, the inclusion of a marker from the same linkage-disequilibrium (LD) block as the marker being tested can decrease power.  This is termed {\it proximal contamination} and \citet{Listgarten2012} proposed an efficient solution.  Intuitively, we would like to use a random effect that excludes any markers from the same LD block as the one being tested.  This can be used by dropping a set of markers from the GSM and recomputing the spectral decomposition.  However, this can be very computationally expensive and we use the algorithm of \citet{Listgarten2012} which reuses the same spectral decompution but which omits the set of proximal contamination markers by modifing the log-loglikelihood calculations of \verb|lrgpr|.\\
\\
Here, \verb|lrgpr| is evaluated by using markers \verb|2:5| in the random effect and testing marker 1.

<<echo=T>>=
dcmp = svd(scale(set_missing_to_mean(X[,2:5])))
fit = lrgpr(y ~ X[,1], decomp=dcmp)
summary(fit)$coefficients
@
\noindent
If the spectral decomposition includes marker 1, then proximal contamination is an issue.  We can pass marker 1 into the \verb|W_til| argument to address this.

<<echo=T>>=
dcmp = svd(scale(set_missing_to_mean(X[,1:5])))
fit = lrgpr(y ~ X[,1], decomp=dcmp, W_til=scale(X[,1]))
summary(fit)$coefficients
@
\noindent
The results of the two evaluations are exactly the same, with the second having the advantage of avoiding the issue of decreased power due to proximal contamination without having to recompute the spectral decomposition and exclude each marker in turn.


\section{Fitting many \texttt{lrgpr} regressions with \texttt{lrgprApply}}

The functionality of \verb|lrgprApply| is the focus of the \pkg{lrgpr} package.  Once the spectral decomposition has been computed, we can perform a genome-wide regression analysis with \verb|lrgprApply| which is analogous to \verb|glmApply|:

<<echo=T,results=hide>>=
# Linear mixed model analysis
pValuesLMM = lrgprApply( y ~ SNP + sex, features=X, decomp=dcmp, terms=2)
@
\noindent
Moreover, \verb|lrgprApply| can be used to fit a regression model with interactions and the \verb|terms| can be set to perform the appropriate hypothesis test:
<<echo=T,results=hide>>=
# Test SNP x sex interaction
pv1 = lrgprApply( y ~ SNP*sex, features=X, decomp=dcmp, terms=4)
@
<<echo=T,results=hide>>=
# Test SNP x SNP interaction
pv2 = lrgprApply( y ~ sex + SNP*X[,1], features=X, decomp=dcmp, terms=3:5)
@
\noindent
The user has a lot of flexabilty to design a custom analysis to address the specific question of his or her study.

\subsection{Proximal contamination}

We can also drop proximal markers in \verb|lrgprApply| using either genetic or physical distance to define the genomic window.  Using the map file from plink:

<<echo=T,results=hide>>=
MAP = read.table( map_file )
@
\noindent
we can call perform a genome-wide analysis:
<<echo=T,results=hide>>=

pValuesLMMprox = lrgprApply( y ~ sex + SNP, features=X, decomp=dcmp, terms=3, 
map=MAP[,c(1,3)], distance=2, dcmp_features=ord[1:k])
@
where entries in \verb|MAP| correspond to the markers in \verb|X|, \verb|map=MAP[,c(1,3)]| indicates the marker names and their position on the genetic map, \verb|distance| determines the size of the window corresponding to the locations in \verb|MAP[,3]|, and \verb|dcmp_features| indicates the indces of \verb|X| used to construct \verb|dcmp|.  Following the standard format for plink map files, the physical location can be used by specifing \verb|map=MAP[,c(1,4)]| and setting \verb|distance| appropriately.

\subsubsection{Interaction model}

When evaluating an interaction model with the formula \verb|y ~ sex + SNP*X[,1]|, the syntax above addresses the proximal contamination due to \verb|SNP|, but not due to \verb|X[,1]|.  We can include additional markers in the proximal contamination set by also specifying \verb|W_til|:

<<echo=T,results=hide>>=
# Test SNP x SNP interaction
pv2 = lrgprApply( y ~ sex + SNP*X[,1], features=X, decomp=dcmp, terms=3:5, 
map=MAP[,c(1,3)], distance=2, dcmp_features=ord[1:k], W_til=X[,1])
@

\section{Implementation}

The \pkg{lrgpr} package provides an \proglang{R} interface to high performance computational statistics code written in \proglang{C/C++} that builds off the GNU Scientific Library (GSL).  Linear algebra operations are performed by \proglang{BLAS} and \proglang{LAPACK} and the performance is highly dependent on the library installed on the local machine.  Data is passed from \proglang{R} to the \proglang{C++} backend using \pkg{Rcpp} and \pkg{RcppGSL}.  Parallelization is performed by OpenMP.  Out-of-core processing is faciliated by \pkg{bigmemory}, which stores the full dataset on the hard drive instead of in memory and uses \verb mmap  from the GNU C Library for random data access.

% Re-instate R prompt ">"
<<echo=F>>=
options(prompt = "> ")
options(continue = "+ ")
@

\pagebreak
\renewcommand\refname{References}
 \bibliography{library}{\small}

\end{document}
